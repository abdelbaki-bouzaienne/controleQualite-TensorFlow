# Controle Qualité avec TensorFlow

<div class="group/conversation-turn relative flex w-full min-w-0 flex-col agent-turn"><div class="flex-col gap-1 md:gap-3"><div class="flex max-w-full flex-col flex-grow"><div data-message-author-role="assistant" data-message-id="6cd1063a-6262-4093-a5d1-c6c94a91b2c3" dir="auto" class="min-h-8 text-message flex w-full flex-col items-end gap-2 whitespace-normal break-words [.text-message+&amp;]:mt-5" data-message-model-slug="gpt-4o-mini"><div class="flex w-full flex-col gap-1 empty:hidden first:pt-[3px]"><div class="markdown prose w-full break-words dark:prose-invert light"><h3><strong>Étude de Cas - Contrôle Qualité des Fruits avec TensorFlow</strong></h3><p>L’objectif de cet exemple est de <strong>créer un modèle de contrôle qualité des fruits</strong> dans le domaine agroalimentaire à l'aide de <strong>TensorFlow</strong> et de l'apprentissage profond (Deep Learning). Ce modèle sera capable de <strong>classer les fruits</strong> en fonction de leur qualité (par exemple : "Bon" ou "Défectueux") en utilisant des images prises lors du processus de production.</p><h3><strong>Problématique :</strong></h3><p>Lors de la production de fruits transformés (jus, conserves, etc.), le contrôle qualité est crucial. Des défauts visibles, tels que des meurtrissures, des taches, ou des imperfections, peuvent nuire à la qualité du produit final. L’objectif est de créer un modèle capable d’analyser des <strong>images de fruits</strong> et de prédire leur qualité.</p><h3><strong>Étapes de la création du modèle de contrôle qualité des fruits avec TensorFlow</strong></h3><hr><h3><strong>1. Collecte et Préparation des Données</strong></h3><p>Le premier objectif est de préparer un ensemble de données comprenant des images de fruits étiquetées, qui seront utilisées pour entraîner le modèle.</p><h4><strong>Données nécessaires</strong> :</h4><ul><li><strong>Images de fruits</strong> (par exemple, pommes, oranges, bananes, etc.).</li><li><strong>Étiquettes de qualité</strong> : Les images doivent être étiquetées comme "Bon" ou "Défectueux".</li></ul><p>Ces images peuvent être prises sur la chaîne de production avec une caméra. Chaque image doit être accompagnée d’une étiquette décrivant la qualité du fruit.</p><h4><strong>Exemple de structure des données</strong> :</h4><pre class="!overflow-visible"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary dark:bg-gray-950"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none">markdown</div><div class="sticky top-9 md:top-[5.75rem]"><div class="absolute bottom-0 right-2 flex h-9 items-center"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-sm"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copier le code</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre hljs language-markdown">dataset/
<span class="hljs-code">    bon/
        apple_01.jpg
        apple_02.jpg
        banana_01.jpg
    defecueux/
        apple_03.jpg
        banana_02.jpg
</span></code></div></div></pre><hr><h3><strong>2. Préparation des Images</strong></h3><p>Avant d'utiliser ces données pour entraîner un modèle, nous devons prétraiter les images :</p><ul><li><strong>Redimensionnement</strong> : Redimensionner toutes les images à une taille uniforme.</li><li><strong>Normalisation</strong> : Convertir les valeurs de pixels des images (généralement entre 0 et 255) en valeurs comprises entre 0 et 1 pour améliorer la convergence du modèle.</li></ul><pre class="!overflow-visible"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary dark:bg-gray-950"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none">python</div><div class="sticky top-9 md:top-[5.75rem]"><div class="absolute bottom-0 right-2 flex h-9 items-center"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-sm"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copier le code</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre hljs language-python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.keras.preprocessing.image <span class="hljs-keyword">import</span> ImageDataGenerator

<span class="hljs-comment"># Prétraitement des images : Redimensionnement et normalisation</span>
train_datagen = ImageDataGenerator(
    rescale=<span class="hljs-number">1.</span>/<span class="hljs-number">255</span>,  <span class="hljs-comment"># Normalisation</span>
    rotation_range=<span class="hljs-number">20</span>,
    width_shift_range=<span class="hljs-number">0.2</span>,
    height_shift_range=<span class="hljs-number">0.2</span>,
    shear_range=<span class="hljs-number">0.2</span>,
    zoom_range=<span class="hljs-number">0.2</span>,
    horizontal_flip=<span class="hljs-literal">True</span>,
    fill_mode=<span class="hljs-string">'nearest'</span>
)

train_generator = train_datagen.flow_from_directory(
    <span class="hljs-string">'dataset/'</span>,
    target_size=(<span class="hljs-number">150</span>, <span class="hljs-number">150</span>),  <span class="hljs-comment"># Redimensionner les images</span>
    batch_size=<span class="hljs-number">32</span>,
    class_mode=<span class="hljs-string">'binary'</span>  <span class="hljs-comment"># Les labels sont binaires : Bon ou Défectueux</span>
)
</code></div></div></pre><hr><h3><strong>3. Création du Modèle de Réseau Neuronal Convolutionnel (CNN)</strong></h3><p>Un réseau de neurones convolutif (CNN) est très adapté aux tâches de classification d'images. Nous allons utiliser <strong>TensorFlow</strong> et l'API <strong>Keras</strong> pour définir un modèle de CNN. Le modèle apprendra à extraire des caractéristiques importantes des images (par exemple, les formes, les couleurs, etc.) et à prédire la qualité du fruit.</p><h4><strong>Architecture du modèle</strong> :</h4><ul><li><strong>Convolution 2D</strong> : Apprendre des motifs dans les images.</li><li><strong>MaxPooling</strong> : Réduire les dimensions des cartes de caractéristiques.</li><li><strong>Dense</strong> : Couches entièrement connectées pour la classification.</li></ul><pre class="!overflow-visible"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary dark:bg-gray-950"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none">python</div><div class="sticky top-9 md:top-[5.75rem]"><div class="absolute bottom-0 right-2 flex h-9 items-center"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-sm"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copier le code</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre hljs language-python"><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Conv2D, MaxPooling2D, Flatten, Dense, Dropout

<span class="hljs-comment"># Création du modèle</span>
model = Sequential([
    Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-number">150</span>, <span class="hljs-number">150</span>, <span class="hljs-number">3</span>)),
    MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)),
    Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)),
    Conv2D(<span class="hljs-number">128</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)),
    Flatten(),
    Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">'relu'</span>),
    Dropout(<span class="hljs-number">0.5</span>),  <span class="hljs-comment"># Pour éviter le sur-apprentissage</span>
    Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">'sigmoid'</span>)  <span class="hljs-comment"># Sortie binaire : Bon ou Défectueux</span>
])

<span class="hljs-comment"># Compilation du modèle</span>
model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">'adam'</span>,
              loss=<span class="hljs-string">'binary_crossentropy'</span>,  <span class="hljs-comment"># Perte binaire pour classification binaire</span>
              metrics=[<span class="hljs-string">'accuracy'</span>])
</code></div></div></pre><hr><h3><strong>4. Entraînement du Modèle</strong></h3><p>Maintenant que nous avons défini le modèle, nous allons l'entraîner avec les images étiquetées. Nous utiliserons une <strong>validation croisée</strong> pour évaluer la performance du modèle.</p><pre class="!overflow-visible"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary dark:bg-gray-950"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none">python</div><div class="sticky top-9 md:top-[5.75rem]"><div class="absolute bottom-0 right-2 flex h-9 items-center"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-sm"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copier le code</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre hljs language-python"><span class="hljs-comment"># Entraînement du modèle</span>
history = model.fit(
    train_generator,
    steps_per_epoch=<span class="hljs-number">100</span>,  <span class="hljs-comment"># Nombre d'itérations par époque</span>
    epochs=<span class="hljs-number">10</span>,  <span class="hljs-comment"># Nombre d'époques</span>
    verbose=<span class="hljs-number">1</span>
)
</code></div></div></pre><hr><h3><strong>5. Évaluation du Modèle</strong></h3><p>Une fois le modèle entraîné, nous devons évaluer sa performance sur un ensemble de test. Si nous avons un ensemble de données séparé pour les tests, nous pouvons l’utiliser pour obtenir des métriques comme <strong>l’exactitude</strong> et <strong>la perte</strong>.</p><pre class="!overflow-visible"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary dark:bg-gray-950"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none">python</div><div class="sticky top-9 md:top-[5.75rem]"><div class="absolute bottom-0 right-2 flex h-9 items-center"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-sm"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copier le code</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre hljs language-python"><span class="hljs-comment"># Évaluation sur les données de test</span>
test_datagen = ImageDataGenerator(rescale=<span class="hljs-number">1.</span>/<span class="hljs-number">255</span>)
test_generator = test_datagen.flow_from_directory(
    <span class="hljs-string">'dataset/test/'</span>,
    target_size=(<span class="hljs-number">150</span>, <span class="hljs-number">150</span>),
    batch_size=<span class="hljs-number">32</span>,
    class_mode=<span class="hljs-string">'binary'</span>
)

<span class="hljs-comment"># Évaluer le modèle</span>
score = model.evaluate(test_generator, verbose=<span class="hljs-number">1</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Perte : <span class="hljs-subst">{score[<span class="hljs-number">0</span>]}</span>, Précision : <span class="hljs-subst">{score[<span class="hljs-number">1</span>]}</span>"</span>)
</code></div></div></pre><hr><h3><strong>6. Prédictions sur de Nouvelles Images</strong></h3><p>Une fois le modèle entraîné et évalué, nous pouvons l’utiliser pour faire des prédictions sur de nouvelles images de fruits. Cela permet de classer les fruits comme "Bon" ou "Défectueux" en fonction des critères appris pendant l'entraînement.</p><pre class="!overflow-visible"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary dark:bg-gray-950"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none">python</div><div class="sticky top-9 md:top-[5.75rem]"><div class="absolute bottom-0 right-2 flex h-9 items-center"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-sm"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copier le code</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre hljs language-python"><span class="hljs-keyword">from</span> tensorflow.keras.preprocessing <span class="hljs-keyword">import</span> image
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># Charger une image à prédire</span>
img_path = <span class="hljs-string">'path_to_new_image.jpg'</span>
img = image.load_img(img_path, target_size=(<span class="hljs-number">150</span>, <span class="hljs-number">150</span>))

<span class="hljs-comment"># Convertir l'image en un tableau numpy et normaliser</span>
img_array = image.img_to_array(img) / <span class="hljs-number">255.0</span>
img_array = np.expand_dims(img_array, axis=<span class="hljs-number">0</span>)

<span class="hljs-comment"># Prédiction</span>
prediction = model.predict(img_array)
<span class="hljs-keyword">if</span> prediction[<span class="hljs-number">0</span>] &gt; <span class="hljs-number">0.5</span>:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Le fruit est défectueux."</span>)
<span class="hljs-keyword">else</span>:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Le fruit est bon."</span>)
</code></div></div></pre><hr><h3><strong>7. Conclusion</strong></h3><p>Ce modèle de contrôle qualité des fruits, basé sur <strong>TensorFlow</strong>, permet de classifier efficacement les fruits en fonction de leur qualité à partir d'images. L'utilisation d'un <strong>réseau neuronal convolutif (CNN)</strong> permet d'extraire des caractéristiques importantes des images (comme des défauts visibles) et de prédire la qualité des fruits en temps réel sur la chaîne de production.</p><p><strong>Avantages</strong> :</p><ul><li><strong>Automatisation</strong> du contrôle qualité.</li><li><strong>Réduction des erreurs humaines</strong> dans le tri des fruits.</li><li><strong>Optimisation des coûts</strong> : Les fruits défectueux sont identifiés tôt, ce qui permet de réduire le gaspillage.</li></ul><p>En utilisant <strong>TensorFlow</strong>, les producteurs de fruits peuvent améliorer la <strong>consistance</strong> et la <strong>qualité</strong> de leurs produits, tout en réduisant les coûts associés à la gestion des défauts.</p><hr><h3><strong>Fin de l'exemple</strong></h3></div></div></div></div><div class="mb-2 flex gap-3 empty:hidden -ml-2"><div class="items-center justify-start rounded-xl p-1 flex"><div class="flex items-center"><span class="" data-state="closed"><button class="rounded-lg text-token-text-secondary hover:bg-token-main-surface-secondary" aria-label="Copier" data-testid="copy-turn-action-button"><span class="flex h-[30px] w-[30px] items-center justify-center"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-md-heavy"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg></span></button></span><span class="hidden"></span><button class="cursor-pointer h-[30px] rounded-md px-1 text-token-text-secondary hover:bg-token-main-surface-secondary"><div class="flex items-center pb-0"><span class="overflow-hidden text-clip whitespace-nowrap text-sm" style="opacity: 0; padding-left: 0px; width: 0px; will-change: opacity;">Bon Travail</span></div></button></div></div></div><div class="pr-2 lg:pr-0"></div><div class="mt-3 w-full empty:hidden"><div class="text-center"></div></div></div></div>
